---
title: Reliability for single item measures
date-format: "YYYY-MM-DD"
date: 2023-06-23
date-modified: last-modified
author:
  - name: IJsbrand Leertouwer
    email: leertouwer@uu.nl
    corresponding: true
    orcid: 0000-0003-0866-3725
    affiliations:
      - name: Youth &amp; Family department, Erasmus University Rotterdam
  - name: No√©mi Schuurman
    email: n.k.schuurman@uu.nl
    orcid: 0000-0002-6437-5966
    affiliations:
      - name: Methods &amp; Statistics department, Utrecht University
csl: apa.csl
citation: true
bibliography: resources/reliability_single_references.bib
google-scholar: true
---

::: callout-caution

## This page has not been peer-reviewed yet.

:::

::: {.callout-note}
## Want to cite this page? See [citation info](PageTemplate.html#citation).
:::

This page is about methods for determining the reliability of <i> single item measures </i> (read more about single item measures [here](/items.html)).

Reliability is a prerequisite for the validity of you item (read more [here]). Unreliable measurements can lead to inaccurate and/or biased parameter estimates when you analyse them.

So far, the available methods for determining the reliability of single item measures are based on the test-retest framework. In the following, we first discuss this framework, followed by two methods for estimating reliability for single item measures.

# The test-retest framework
So far, the available methods for determining the reliability of single item measures are based on the test-retest framework.

The main idea behind the test-retest framework is that when a construct does not change, repeated measurements of that construct should produce the same result. In that case, the instrument is reliable. If the results of the repeated measurements differ, this can be ascribed to measurement error.

In classical test theory, this implies that each measurement $y_t$ at timepoint $t$ consists of a stable part of the score $\theta$ that is refered to as the *true score*, and a *measurement error* $\epsilon_t$ that is specific to the measurement:

$$
y_{t} = \theta + \epsilon_{t}.
$$
In this scenario, measurement error can be separated from true scores by determining what part of the measurements is stable of time, and what is variable over time.

## The test-retest framework for ILD

The challenge for ILD is that the true score is often expected to vary over time ($\theta$ should also get a subscript $t$ in the previous equation). As such, we need a different way to distinguish the variance in the true score from variance due to measurement error for a single item in our repeated measures, if we want to use a test-retest approach.

This generally requires making some assumptions about how the true process varies over time, next to how the measurement error varies over time. Leveraging these assumptions, the two sources of variance can be distinguished from each other, and we can estimate the reliability of an approach.

Below we will discuss two methods that do this, and can be used for measurements of single items and single (or multiple) participants: The measurement error autoregressive model and the immediate test-retest method. 

::: {.callout-note collapse="true"}
## Read more: Other approaches to reliability (for muliple item measures)

- [Internal Consistency Reliability]

:::


# The Measurement Error Autoregressive model
<!-- Ik denk dat dit een stuk vriendelijker uitgelegd kan worden, met een wat rustigere/logischere opbouw, maar dat kunnen we later nog aanpassen (ik zal later een suggestie/edit doen). Fijne voorbeelden. -->

In the Measurement Error Autoregressive model (MEAR(1)) model [@schuurman_incorporating_2015], the true score is assumed to consist of a stable mean $\mu$ and an autoregressive process of order 1. Specifically, at each timepoint $t$, a true score $\tilde{y}_t$ is predicted by the previous true score $\tilde{y}_{t-1}$ through autoregressive parameter $\phi$, resulting in a dynamic error $\omega_t$. The dynamic errors are assumed to come from a normal distribution with a mean of zero and variance  $\sigma_\omega^2$. The key property of dynamic errors is that they carry over to the next measurement through the autoregressive process. 

<!-- Misschien iets zeggen over hoe dynamic 'error' misschien niet het beste woord is omdat het deel is van de ware score, en dat sommige mensen dit dus ook innovations noemen, of je zou het dynamic residuals kunnen noemen -->

::: {.callout-tip collapse="true"}

## Example: dynamic error

Ayoko wants to study the dynamics in her enthusiasm. She gathers personal measurements on her phone in the morning, in the afternoon and in the evening. On Sunday afternoon she goes to the cinema and greatly enjoys a movie. This results in a spike in her enthusiasm. The effect of seeing this movie on her enthusiasm still lingers in the evening. In other words, the autoregressive parameter has "carried over" this "dynamic error".

:::

The variance of the true score is given by:

$$
\sigma_{\tilde{y}}^2 = \frac{\sigma_\omega^2}{1-\phi^2}.
$$
In addition to a true score $\tilde{y}_t$, each measurement $y_t$ contains a part that is due to measurement error $\epsilon_t$. These errors do not carry over to the next measurement (see figure below). 

\
<div style="text-align: center;">
<img src="images\MEAR(1).png" style="width: 500px; height: auto;">
<br>
<!-- <figcaption> Graphical representation of the MEAR(1) model</figcaption> -->
</div>
\

The measurement errors are assumed to come from a distribution with mean zero and variance $\sigma_\epsilon^2$.

::: {.callout-tip collapse="true"}

## Example: measurement error

On Tuesday morning, Ayoko's finger slips when rating her enthusiasm on her phone, and she accidentally records the highest possible value. The effect of this error is limited to this single measurement and will not affect the next measurement. 

:::

In order to calculate the reliability of the construct we can divide the variance in the true score by the total variance:

$$
rel(y) = \frac{\sigma_{\tilde{y}}^2}{\sigma_{\tilde{y}}^2 + \sigma_\epsilon^2}
$$

However, it is important to note that dynamic errors $\omega_t$ and measurement errors $\epsilon_t$ can only be distinguished from each other by the fact that the effect of the dynamic errors carries over to the next measurement. This has several important implications.

* First, it means that any unobserved effect that is not carried over to the next measurement is ascribed to measurement error. As such, the reliability estimate of the MEAR(1) model provides a lower bound.

* Second, it means that when the autoregressive parameter is zero and dynamic errors do not carry over, the model is not identified.

::: {.callout-tip collapse="true"}

## Example: measurement error?

On Thursday afternoon, Ayoko has a tasty cookie right before a measuring her enthusiasm. The effect of this cookie on her enthousiasm likely does not carry over to the  measurement in the evening. However, the cookie did temporarily boost her enthusiasm. What would have happened if Ayoko gathered measurements every 5 minutes? 

:::

The example above demonstrates that like other discrete timeseries models, parameter values in the MEAR(1) model depend on the interval under study. Therefore, it is important to carefully select the time interval for your study.



::: {.callout-note collapse="true"}

## Read more: choosing a relevant time interval

- [The timescale of a construct](/)

- [Name related page 2](/)

:::

<!-- Ik zou hier nog iets opmerken over dat je dit met elk willekeurig dynamisch model kan doen, niet alleen ar(1) modellen, bv in een aparte subsubsectie 'extensies', oid -->

The MEAR(1) model can be extended to multivariate data that follow a hierarchical structure [@schuurman_measurement_2019].


# The immediate TRT method

In the immediate test-retest (TRT) method [@dejonckheere_assessing_2022], the sampling design is altered such that measurements of the item of interest are quickly followed by another measurement. 

<!-- onderstaande zin meer een voorbeeld van hoe je dat zou kunnen doen op een zinnge manier. Gebruik wat meer zinnen om uit te leggen wat ze doen, dit is nog niet duidelijk. Misschien is het goed om hier een example box van te maken met ref naar dejonckheere. -->
For example, .. do this by ..  within a questionnaire of several items, one or some items are repeated with only a few items in between. 

The reasoning is that it is unlikely that the true score changed between these measurements. Hence, any difference between these repeated measurements, which are taken very close in time, are considered to be measurement error (the unreliable part).

Specifically, under this assumption measurement error variance can be expressed as the expected value (i.e., average) of the squared differences between original and repeated items, divided by two:

$$
\sigma_\epsilon^2 = \frac{E[\Delta_{trt}^2]}{2}
$$
In order to calculate reliability, this measurement error can be divided by the variance of all scores that have a replicate measurement:

$$
rel(y) = \frac{\sigma_\epsilon^2}{\sigma_{trt}^2}
$$

The clear benefit of this method is that can easily be calculated. However, it does require some additional assumptions:

-  1. The first assumption was already mentioned; this is that the true score does not change between the initial and replicate measurement.

::: {.callout-tip collapse="true"}

## Example: No measurement error?

Tobias is not particularly interested in the dynamics of his experiences, but rather in his average experiences over a week of time. He also gathers personal measurements in the morning, afternoon and evening, and wants to know how reliable his responses are. He uses the immediate test-retest method in order to get an estimate. Like Ayoko, Tobias likes cookies. During his afternoon he eats a cookie just in between the original measurement of enthusiasm and the repetition. What does this do for the estimated measurement error?

:::

2. There are no recall effects among the initial and replicate measurement that distort distinguishing the true scores and measurement errors. 



::: {.callout-tip collapse="true"}

## Example 2: No measurement error?

During a particular measurement, Tobias is not very sure how enthusiastic he feels. He decides to just go with a number and feels that 45 should be relatively close. Quickly after giving this rating Tobias is presented with another question about his enthusiasm. Didn't I already fill this in? Tobias thinks to himself. What was it again? 45? He fills in 45 again.

[better example will follow]
<!-- I think this example is fine, but it can be made more explicit/obvious why this is a problem; He feels the same at each measurement, but 45 is not the true score, and still repeats it. This will result in overestimating reliability -->

<!-- Here are additional options: There could be one where the participants remembers the initial score and repeats it although they feel differently at the replicate measure, or perhaps one where they feel different, realize this change, and then go back to the first score and change their initial rating to be consistent with the replicate measurement (although this latter one does not have to affect the reliability estimate in a negative way, it surely messes up your measurements). etc --> 

:::

The example above demonstrates how the reliability estimate of the immediate test-retest method may result in a inflated estimate of the reliability. This estimate may thus represent an upper bound of the reliability.
<!-- it could be both inflated or deflated or neither  depending on what the participants do , right?
Note, violating the first assumption would deflate reliability, so lower bound. So hard to say if it is an upper or lower bound estimate overall
-->

<!-- Ergens moet nog iets over dat je met het ene kan corrigeren voor meetfout en schatten van betrouwbaarheid, en voor de ander alleen schatten. Even bedenken waar. Evt een tabel met voor/nadelen van elke approach oid. -->


::: {.callout-note collapse="true"}

## Read more: Practical application

<!-- Ik denk dat dit bij beide methods moet (nu zie je dit alleen onder TRT) -->


- Scripts for R and Mplus are available in the supplementary materials of @leertouwer_practical

:::

<!-- deze onderste categorie lijkt hier niet zo relevant. Misschien moeten we het hier dus weglaten (bij deze)

# Practical Considerations

The following practical considerations are also important for the decision about determining reliability for single item measures, but are not considered further on this website:-->


